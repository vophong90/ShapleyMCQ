import { NextRequest, NextResponse } from "next/server";

export const runtime = "nodejs";

type EduFitPayload = {
  stem: string;
  correct_answer: string;
  distractors: string[];
  explanation: string;
  learner_level?: string;
  bloom_level?: string;
  llos_text?: string;
  specialty_name?: string;
};

export async function POST(req: NextRequest) {
  try {
    const body = (await req.json().catch(() => null)) as EduFitPayload | null;

    if (
      !body ||
      !body.stem?.trim() ||
      !body.correct_answer?.trim() ||
      !Array.isArray(body.distractors) ||
      body.distractors.length === 0
    ) {
      return NextResponse.json(
        {
          error:
            "Thi·∫øu d·ªØ li·ªáu MCQ cho Educational Fit (stem, correct_answer, distractors).",
        },
        { status: 400 }
      );
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      console.error("OPENAI_API_KEY kh√¥ng t·ªìn t·∫°i trong m√¥i tr∆∞·ªùng server");
      return NextResponse.json(
        { error: "Thi·∫øu OPENAI_API_KEY tr√™n server" },
        { status: 500 }
      );
    }

    // C√≥ th·ªÉ override b·∫±ng OPENAI_MCQ_MODEL, m·∫∑c ƒë·ªãnh d√πng gpt-5.1
    const model = (process.env.OPENAI_MCQ_MODEL || "gpt-5.1").trim();

    const {
      stem,
      correct_answer,
      distractors,
      explanation,
      learner_level,
      bloom_level,
      llos_text,
      specialty_name,
    } = body;

    const prompt = `
B·∫°n l√† chuy√™n gia gi√°o d·ª•c y khoa v√† thi·∫øt k·∫ø ƒë·ªÅ thi.

Nhi·ªám v·ª•: ƒê√°nh gi√° m·ª©c ƒë·ªô "ph√π h·ª£p gi√°o d·ª•c" (Educational Fit) c·ªßa c√¢u MCQ sau v·ªõi:
- B·∫≠c h·ªçc (learner level)
- M·ª©c Bloom m·ª•c ti√™u
- Danh s√°ch LLOs c·ªßa b√†i h·ªçc

Th√¥ng tin:
- Chuy√™n ng√†nh: ${specialty_name || "Y h·ªçc c·ªï truy·ªÅn / y khoa"}
- B·∫≠c h·ªçc: ${learner_level || "Kh√¥ng r√µ"}
- Bloom m·ª•c ti√™u: ${bloom_level || "Kh√¥ng r√µ"}

C√¢u MCQ:
- Stem: ${stem}
- Correct answer: ${correct_answer}
- Distractors: ${distractors
      .map((d, i) => `(${i + 1}) ${d}`)
      .join("; ")}
- Explanation: ${explanation}

LLOs (m·ªói d√≤ng l√† m·ªôt LLO):
${llos_text || "(kh√¥ng cung c·∫•p r√µ, h√£y suy lu·∫≠n t·ªïng qu√°t)"}

Y√äU C·∫¶U:
1) Suy lu·∫≠n m·ª©c Bloom th·ª±c t·∫ø c·ªßa c√¢u h·ªèi n√†y (inferred_bloom).
2) So s√°nh v·ªõi Bloom m·ª•c ti√™u (bloom_level):
   - bloom_match: "good" | "too_low" | "too_high" (ho·∫∑c m√¥ t·∫£ kh√°c n·∫øu c·∫ßn).
3) ƒê√°nh gi√° ƒë·ªô ph√π h·ª£p v·ªõi b·∫≠c h·ªçc:
   - level_fit: "good" | "too_easy" | "too_hard" (ho·∫∑c m√¥ t·∫£ kh√°c).
4) Ph√¢n t√≠ch m·ª©c ƒë·ªô "coverage" c·ªßa c√¢u h·ªèi ƒë·ªëi v·ªõi t·ª´ng LLO:
   - llo: n·ªôi dung LLO (string).
   - coverage: "direct" | "indirect" | "none".
   - comment: nh·∫≠n x√©t ng·∫Øn (t·∫°i sao).
5) ƒê∆∞a ra recommendations: m·∫£ng string, m·ªói string l√† 1 g·ª£i √Ω c·ª• th·ªÉ ƒë·ªÉ:
   - n√¢ng/gi·∫£m m·ª©c Bloom cho ph√π h·ª£p
   - ƒëi·ªÅu ch·ªânh stem/distractors/explanation ƒë·ªÉ align t·ªët h∆°n v·ªõi LLOs v√† b·∫≠c h·ªçc.

TR·∫¢ V·ªÄ ƒê√öNG ƒê·ªäNH D·∫†NG JSON THU·∫¶N (KH√îNG TEXT TH·ª™A):

{
  "inferred_bloom": "apply / analyze / evaluate / ...",
  "bloom_match": "good" | "too_low" | "too_high",
  "level_fit": "good" | "too_easy" | "too_hard",
  "summary": "ƒëo·∫°n t√≥m t·∫Øt ng·∫Øn b·∫±ng ti·∫øng Vi·ªát",
  "llo_coverage": [
    {
      "llo": "string",
      "coverage": "direct" | "indirect" | "none",
      "comment": "string"
    }
  ],
  "recommendations": [
    "string",
    "string"
  ]
}
`.trim();

    // üöÄ G·ªçi CHAT COMPLETIONS API ‚Äì JSON mode
    const openaiRes = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model,
        response_format: { type: "json_object" },
        messages: [
          {
            role: "system",
            content:
              "B·∫°n l√† tr·ª£ l√Ω gi√°o d·ª•c y khoa, CH·ªà tr·∫£ l·ªùi b·∫±ng JSON ƒë√∫ng schema y√™u c·∫ßu.",
          },
          {
            role: "user",
            content: prompt,
          },
        ],
      }),
    });

    const data = await openaiRes.json().catch(() => null);

    if (!openaiRes.ok) {
      console.error("OpenAI error t·∫°i /api/mcqs/edu-fit:", data);
      return NextResponse.json(
        {
          error: "L·ªói khi g·ªçi GPT (edu-fit)",
          detail: JSON.stringify(data, null, 2),
        },
        { status: 500 }
      );
    }

    const content = data?.choices?.[0]?.message?.content;

    if (!content || typeof content !== "string") {
      console.error("Kh√¥ng c√≥ message.content h·ª£p l·ªá (edu-fit):", data);
      return NextResponse.json(
        { error: "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c content h·ª£p l·ªá t·ª´ GPT (edu-fit)" },
        { status: 500 }
      );
    }

    let parsed: any;
    try {
      parsed = JSON.parse(content);
    } catch (e) {
      console.error("JSON parse error ·ªü /api/mcqs/edu-fit:", e, "raw:", content);
      return NextResponse.json(
        { error: "GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá (edu-fit)", raw: content },
        { status: 500 }
      );
    }

    return NextResponse.json(parsed, { status: 200 });
  } catch (err: any) {
    console.error("edu-fit error:", err);
    return NextResponse.json(
      { error: "L·ªói server Educational Fit.", detail: String(err) },
      { status: 500 }
    );
  }
}
