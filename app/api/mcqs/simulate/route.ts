import { NextRequest, NextResponse } from "next/server";

export const runtime = "nodejs";

export async function POST(req: NextRequest) {
  try {
    const body = await req.json().catch(() => null);
    const { stem, correct_answer, distractors, explanation, N } = body || {};

    if (
      !stem ||
      !String(stem).trim() ||
      !correct_answer ||
      !String(correct_answer).trim() ||
      !Array.isArray(distractors)
    ) {
      return NextResponse.json(
        { error: "Thi·∫øu stem, correct_answer ho·∫∑c distractors." },
        { status: 400 }
      );
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      console.error("OPENAI_API_KEY kh√¥ng t·ªìn t·∫°i trong m√¥i tr∆∞·ªùng server");
      return NextResponse.json(
        { error: "Thi·∫øu OPENAI_API_KEY." },
        { status: 500 }
      );
    }

    const model = (process.env.OPENAI_MCSIM_MODEL || "gpt-5.1").trim();

    // t·ªïng s·ªë "sinh vi√™n ·∫£o"
    const totalN = typeof N === "number" && N > 0 ? N : 1200;

    // Map option labels
    const options = [correct_answer, ...distractors];
    const labels = ["A", "B", "C", "D"];

    const labeledOptions = options.map((text: string, idx: number) => ({
      label: labels[idx],
      text,
      is_correct: idx === 0,
    }));

    const personas = [
      {
        name: "Expert",
        description:
          "B√°c sƒ©/ sinh vi√™n r·∫•t gi·ªèi, hi·ªÉu s√¢u l√Ω thuy·∫øt v√† l√¢m s√†ng, m·∫Øc l·ªói r·∫•t √≠t.",
      },
      {
        name: "Proficient",
        description:
          "Ng∆∞·ªùi h·ªçc kh√°, n·∫Øm t·ªët ki·∫øn th·ª©c c·ªët l√µi, ƒë√¥i khi nh·∫ßm ·ªü chi ti·∫øt kh√≥.",
      },
      {
        name: "Average",
        description:
          "Ng∆∞·ªùi h·ªçc trung b√¨nh, n·∫Øm ƒë∆∞·ª£c √Ω ch√≠nh nh∆∞ng d·ªÖ b·ªã distractor ƒë√°nh l·ª´a.",
      },
      {
        name: "Novice",
        description:
          "M·ªõi h·ªçc, ch∆∞a h·ªá th·ªëng h√≥a ki·∫øn th·ª©c, hay nh·∫ßm l·∫´n kh√°i ni·ªám.",
      },
      {
        name: "Weak",
        description:
          "√çt h·ªçc, ch·ªß y·∫øu d·ª±a v√†o ƒëo√°n m√≤ ho·∫∑c ·∫•n t∆∞·ª£ng m∆° h·ªì, r·∫•t d·ªÖ sai.",
      },
      {
        name: "Guesser",
        description:
          "Ho√†n to√†n ƒëo√°n m√≤, kh√¥ng c√≥ ki·∫øn th·ª©c li√™n quan, ch·ªçn ng·∫´u nhi√™n.",
      },
    ];

    const mcqBlock = `
STEM:
${stem}

OPTIONS:
${labeledOptions.map((o) => `${o.label}. ${o.text}`).join("\n")}

Correct answer: ${labeledOptions[0].label}
Explanation (n·∫øu c√≥):
${explanation || "(kh√¥ng c√≥)"}
`.trim();

    const personaText = personas
      .map((p, idx) => `${idx + 1}. ${p.name}: ${p.description}`)
      .join("\n");

    const prompt = `
B·∫°n l√† chuy√™n gia ƒëo l∆∞·ªùng ƒë√°nh gi√° trong gi√°o d·ª•c Y khoa.

Nhi·ªám v·ª•:
- V·ªõi m·ªói ki·ªÉu ng∆∞·ªùi h·ªçc (persona) d∆∞·ªõi ƒë√¢y, h√£y ∆∞·ªõc l∆∞·ª£ng X√ÅC SU·∫§T h·ªç ch·ªçn t·ª´ng ph∆∞∆°ng √°n A, B, C, D cho c√¢u MCQ ƒë√£ cho.
- X√°c su·∫•t ph·∫£i >=0 v√† t·ªïng 4 ph∆∞∆°ng √°n = 1.
- Expert c√≥ x√°c su·∫•t ch·ªçn ƒë√°p √°n ƒë√∫ng r·∫•t cao.
- Weak/Guesser ch·ªçn sai nhi·ªÅu h∆°n, th∆∞·ªùng t·∫≠p trung v√†o distractors "h·∫•p d·∫´n".
- Kh√¥ng c·∫ßn t·∫°o d·ªØ li·ªáu Monte Carlo, ch·ªâ c·∫ßn tr·∫£ v·ªÅ ph√¢n b·ªë x√°c su·∫•t (probability) cho t·ª´ng persona.

C√°c persona:
${personaText}

C√¢u MCQ:
${mcqBlock}

Y√äU C·∫¶U TR·∫¢ V·ªÄ JSON ƒê√öNG C·∫§U TR√öC (KH√îNG TH√äM FIELD KH√ÅC):

{
  "personas": [
    {
      "name": "Expert",
      "probs": { "A": 0.9, "B": 0.05, "C": 0.03, "D": 0.02 }
    },
    {
      "name": "Proficient",
      "probs": { "A": 0.8, "B": 0.1, "C": 0.05, "D": 0.05 }
    }
    ...
  ]
}
`.trim();

    // üöÄ G·ªçi Chat Completions ‚Äì JSON mode gi·ªëng /api/llo-eval
    const openaiRes = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model,
        response_format: { type: "json_object" },
        messages: [
          {
            role: "system",
            content:
              "B·∫°n l√† chuy√™n gia ƒëo l∆∞·ªùng ƒë√°nh gi√° trong gi√°o d·ª•c y khoa, CH·ªà tr·∫£ l·ªùi b·∫±ng JSON ƒë√∫ng schema y√™u c·∫ßu.",
          },
          {
            role: "user",
            content: prompt,
          },
        ],
      }),
    });

    const data = await openaiRes.json().catch(() => null);

    if (!openaiRes.ok) {
      console.error("OpenAI error t·∫°i /api/mcqs/simulate:", data);
      return NextResponse.json(
        {
          error: "L·ªói khi g·ªçi GPT Monte Carlo persona.",
          detail: JSON.stringify(data, null, 2),
        },
        { status: 500 }
      );
    }

    const content = data?.choices?.[0]?.message?.content;
    if (!content || typeof content !== "string") {
      console.error("Kh√¥ng c√≥ message.content h·ª£p l·ªá (simulate):", data);
      return NextResponse.json(
        { error: "GPT kh√¥ng tr·∫£ v·ªÅ n·ªôi dung persona probs." },
        { status: 500 }
      );
    }

    let parsed: any;
    try {
      parsed = JSON.parse(content);
    } catch (e) {
      console.error(
        "JSON persona probs kh√¥ng h·ª£p l·ªá (simulate):",
        e,
        "raw:",
        content
      );
      return NextResponse.json(
        { error: "JSON persona probs kh√¥ng h·ª£p l·ªá.", raw: content },
        { status: 500 }
      );
    }

    const personaProbs: { name: string; probs: Record<string, number> }[] =
      parsed.personas || [];

    // =============== MONTE CARLO SAMPLING ===============
    const response_matrix: any[] = [];
    const accuracy_summary: { persona: string; accuracy: number; total: number }[] =
      [];

    const personaNames = personas.map((p) => p.name);
    const N_per_persona = Math.max(
      1,
      Math.floor(totalN / Math.max(1, personaNames.length))
    );

    function sampleFromProbs(probs: Record<string, number>): string {
      const keys = ["A", "B", "C", "D"];
      const cumulative: number[] = [];
      let acc = 0;
      for (const k of keys) {
        acc += probs[k] ?? 0;
        cumulative.push(acc);
      }
      if (acc <= 0) {
        // fallback ƒë·ªÅu
        const r = Math.random();
        if (r < 0.25) return "A";
        if (r < 0.5) return "B";
        if (r < 0.75) return "C";
        return "D";
      }
      const r = Math.random() * acc;
      for (let i = 0; i < keys.length; i++) {
        if (r <= cumulative[i]) return keys[i];
      }
      return "A";
    }

    for (const personaName of personaNames) {
      const pObj =
        personaProbs.find((p) => p.name === personaName) ||
        personaProbs[0] || {
          name: personaName,
          probs: { A: 0.25, B: 0.25, C: 0.25, D: 0.25 },
        };

      const probs = pObj.probs || {
        A: 0.25,
        B: 0.25,
        C: 0.25,
        D: 0.25,
      };

      let correctCount = 0;

      for (let i = 0; i < N_per_persona; i++) {
        const chosenLabel = sampleFromProbs(probs);
        const idx = labels.indexOf(chosenLabel);
        const chosenText =
          idx >= 0 && idx < options.length ? options[idx] : options[0];

        const isCorrect = chosenLabel === labeledOptions[0].label;
        if (isCorrect) correctCount++;

        response_matrix.push({
          persona: personaName,
          chosen_option: chosenLabel,
          chosen_text: chosenText,
          is_correct: isCorrect,
        });
      }

      accuracy_summary.push({
        persona: personaName,
        accuracy: correctCount / N_per_persona,
        total: N_per_persona,
      });
    }

    return NextResponse.json(
      {
        options: labeledOptions,
        personas: personaProbs,
        N_per_persona,
        response_matrix,
        accuracy_summary,
      },
      { status: 200 }
    );
  } catch (err: any) {
    console.error("L·ªói Monte Carlo Simulator:", err);
    return NextResponse.json(
      { error: "L·ªói Monte Carlo Simulator", detail: String(err) },
      { status: 500 }
    );
  }
}
