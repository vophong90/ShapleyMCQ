// app/api/llo-eval/route.ts
import { NextRequest, NextResponse } from "next/server";

export const runtime = "nodejs";

type LloEvalRequest = {
  specialty_name?: string;
  learner_level?: string;
  bloom_level?: string;
  llos_text?: string;
};

export async function POST(req: NextRequest) {
  try {
    const body = (await req.json().catch(() => null)) as LloEvalRequest | null;

    if (!body) {
      return NextResponse.json(
        { error: "Body request tr·ªëng" },
        { status: 400 }
      );
    }

    const { learner_level, bloom_level, llos_text, specialty_name } = body;

    if (!learner_level || !bloom_level || !llos_text || !llos_text.trim()) {
      return NextResponse.json(
        { error: "Thi·∫øu learner_level, bloom_level ho·∫∑c llos_text" },
        { status: 400 }
      );
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      console.error("OPENAI_API_KEY kh√¥ng t·ªìn t·∫°i trong m√¥i tr∆∞·ªùng server");
      return NextResponse.json(
        { error: "Thi·∫øu OPENAI_API_KEY tr√™n server" },
        { status: 500 }
      );
    }

    // C√≥ th·ªÉ override b·∫±ng OPENAI_LLO_MODEL, m·∫∑c ƒë·ªãnh d√πng gpt-5.1
    const model = (process.env.OPENAI_LLO_MODEL || "gpt-5.1").trim();

    const prompt = `
B·∫°n l√† chuy√™n gia gi√°o d·ª•c y khoa, am hi·ªÉu thang Bloom (revised) v√† c√°c b·∫≠c ƒë√†o t·∫°o y khoa.

Nhi·ªám v·ª• c·ªßa b·∫°n:

1) Ph√¢n t√≠ch t·ª´ng LLO (learning outcome) ƒë∆∞·ª£c cung c·∫•p (m·ªói d√≤ng l√† m·ªôt LLO).
2) Suy lu·∫≠n m·ª©c Bloom th·ª±c t·∫ø c·ªßa t·ª´ng LLO d·ª±a tr√™n:
   - ƒê·ªông t·ª´ ch√≠nh (verb) trong c√¢u.
   - N·ªôi dung ki·∫øn th·ª©c / k·ªπ nƒÉng m√† LLO h∆∞·ªõng t·ªõi.
3) So s√°nh m·ª©c Bloom th·ª±c t·∫ø v·ªõi m·ª©c Bloom m·ª•c ti√™u do ng∆∞·ªùi d√πng ch·ªçn.
4) ƒê√°nh gi√° ƒë·ªô ph√π h·ª£p c·ªßa LLO v·ªõi b·∫≠c ƒë√†o t·∫°o:
   - undergrad  = sinh vi√™n y khoa (ƒë·∫°i h·ªçc)
   - postgrad   = h·ªçc vi√™n sau ƒë·∫°i h·ªçc (BS n·ªôi tr√∫, CK1, CK2‚Ä¶)
   - phd        = nghi√™n c·ª©u sinh
5) G√≥p √Ω ng·∫Øn g·ªçn, c·ª• th·ªÉ cho t·ª´ng LLO:
   - N·∫øu Bloom qu√° th·∫•p ho·∫∑c qu√° cao so v·ªõi m·ª•c ti√™u ‚Üí ƒë·ªÅ xu·∫•t c√°ch ch·ªânh.
   - N·∫øu m·ª©c ƒë·ªô kh√≥ kh√¥ng ph√π h·ª£p b·∫≠c h·ªçc ‚Üí g·ª£i √Ω n√¢ng/gi·∫£m ƒë·ªô ph·ª©c t·∫°p.

B·∫°n PH·∫¢I tr·∫£ l·ªùi CH·ªà b·∫±ng JSON v·ªõi c·∫•u tr√∫c CH√çNH X√ÅC nh∆∞ sau, kh√¥ng th√™m tr∆∞·ªùng kh√°c:

{
  "overall_comment": "string",
  "items": [
    {
      "llo": "string",
      "inferred_bloom": "remember|understand|apply|analyze|evaluate|create",
      "bloom_match": "good|too_low|too_high",
      "level_fit": "good|too_easy|too_hard",
      "comments": "string"
    }
  ]
}

D·ªØ li·ªáu ƒë·∫ßu v√†o:

- Chuy√™n ng√†nh: ${specialty_name || "kh√¥ng r√µ"}
- B·∫≠c ƒë√†o t·∫°o (learner_level): ${learner_level}
- M·ª©c Bloom m·ª•c ti√™u (bloom_level): ${bloom_level}

C√°c LLO (m·ªói d√≤ng l√† m·ªôt LLO):

${llos_text}
`.trim();

    // üöÄ G·ªçi CHAT COMPLETIONS API ‚Äì JSON mode
    const openaiRes = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model,
        response_format: { type: "json_object" },
        messages: [
          {
            role: "system",
            content:
              "B·∫°n l√† tr·ª£ l√Ω gi√°o d·ª•c y khoa, CH·ªà tr·∫£ l·ªùi b·∫±ng JSON ƒë√∫ng schema y√™u c·∫ßu."
          },
          {
            role: "user",
            content: prompt
          }
        ]
      })
    });

    const data = await openaiRes.json().catch(() => null);

    if (!openaiRes.ok) {
      console.error("OpenAI error t·∫°i /api/llo-eval:", data);
      return NextResponse.json(
        {
          error: "L·ªói khi g·ªçi GPT",
          detail: JSON.stringify(data, null, 2)
        },
        { status: 500 }
      );
    }

    const content = data?.choices?.[0]?.message?.content;

    if (!content || typeof content !== "string") {
      console.error("Kh√¥ng c√≥ message.content h·ª£p l·ªá:", data);
      return NextResponse.json(
        { error: "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c content h·ª£p l·ªá t·ª´ GPT" },
        { status: 500 }
      );
    }

    let parsed: any;
    try {
      parsed = JSON.parse(content);
    } catch (e) {
      console.error("JSON parse error ·ªü /api/llo-eval:", e, "raw:", content);
      return NextResponse.json(
        { error: "GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá", raw: content },
        { status: 500 }
      );
    }

    return NextResponse.json(parsed, { status: 200 });
  } catch (e: any) {
    console.error("L·ªói server /api/llo-eval:", e);
    return NextResponse.json(
      { error: "L·ªói server", detail: String(e?.message || e) },
      { status: 500 }
    );
  }
}
