import { NextRequest, NextResponse } from "next/server";

export const runtime = "nodejs";

type LloEvalRequest = {
  specialty_name?: string;
  learner_level: string; 
  bloom_level: string;
  llos_text: string; 
};

export async function POST(req: NextRequest) {
  try {
    const body = (await req.json()) as LloEvalRequest;

    if (!body.learner_level || !body.bloom_level || body.llos_text.trim() === "") {
      return NextResponse.json(
        { error: "Thi·∫øu learner_level, bloom_level ho·∫∑c llos_text" },
        { status: 400 }
      );
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      return NextResponse.json(
        { error: "Thi·∫øu OPENAI_API_KEY tr√™n server" },
        { status: 500 }
      );
    }

    // Model cao nh·∫•t b·∫°n ƒëang d√πng
    const model =
      process.env.OPENAI_LLO_MODEL?.trim() || "gpt-5.1";

    const { learner_level, bloom_level, llos_text, specialty_name } = body;

    const prompt = `
B·∫°n l√† chuy√™n gia gi√°o d·ª•c y khoa, am hi·ªÉu thang Bloom (revised) v√† c√°c b·∫≠c ƒë√†o t·∫°o y khoa.

Nhi·ªám v·ª•:
1) Ph√¢n t√≠ch t·ª´ng LLO (learning outcome) ƒë∆∞·ª£c cung c·∫•p.
2) Suy lu·∫≠n m·ª©c Bloom th·ª±c t·∫ø c·ªßa t·ª´ng LLO d·ª±a tr√™n ƒë·ªông t·ª´ & n·ªôi dung.
3) ƒê√°nh gi√° m·ª©c Bloom ng∆∞·ªùi d√πng ch·ªçn c√≥ ph√π h·ª£p kh√¥ng.
4) ƒê√°nh gi√° ƒë·ªô ph√π h·ª£p c·ªßa LLO v·ªõi b·∫≠c ƒë√†o t·∫°o:
   - undergrad = sinh vi√™n y khoa
   - postgrad = h·ªçc vi√™n sau ƒë·∫°i h·ªçc
   - phd = nghi√™n c·ª©u sinh

Tr·∫£ l·ªùi CH·ªà b·∫±ng JSON v·ªõi c·∫•u tr√∫c:

{
  "overall_comment": "string",
  "items": [
    {
      "llo": "string",
      "inferred_bloom": "remember|understand|apply|analyze|evaluate|create",
      "bloom_match": "good|too_low|too_high",
      "level_fit": "good|too_easy|too_hard",
      "comments": "string"
    }
  ]
}

Kh√¥ng ƒë∆∞·ª£c th√™m tr∆∞·ªùng n√†o kh√°c.

D·ªØ li·ªáu:
- Chuy√™n ng√†nh: ${specialty_name || "kh√¥ng r√µ"}
- B·∫≠c ƒë√†o t·∫°o: ${learner_level}
- M·ª©c Bloom m·ª•c ti√™u: ${bloom_level}

C√°c LLO:
${llos_text}
`.trim();

    // üî• GPT-5.1 API m·ªõi ‚Äì kh√¥ng d√πng messages n·ªØa
    const response = await fetch("https://api.openai.com/v1/responses", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model,
        input: prompt
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("OpenAI error:", errorText);
      return NextResponse.json(
        { error: "L·ªói khi g·ªçi GPT", detail: errorText },
        { status: 500 }
      );
    }

    const data = await response.json();
    const content = data.output_text;

    if (!content) {
      return NextResponse.json(
        { error: "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c content t·ª´ GPT" },
        { status: 500 }
      );
    }

    let parsed;
    try {
      parsed = JSON.parse(content);
    } catch (e) {
      console.error("JSON parse error:", e, "raw:", content);
      return NextResponse.json(
        { error: "GPT tr·∫£ v·ªÅ JSON kh√¥ng h·ª£p l·ªá", raw: content },
        { status: 500 }
      );
    }

    return NextResponse.json(parsed, { status: 200 });

  } catch (e: any) {
    console.error(e);
    return NextResponse.json(
      { error: "L·ªói server", detail: String(e?.message || e) },
      { status: 500 }
    );
  }
}
